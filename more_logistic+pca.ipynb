{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPW9tWu57O2PpzlTOhr8VCf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njweg/Machine-Learning-Exercises/blob/main/more_logistic%2Bpca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_PAFtkdaaOs"
      },
      "outputs": [],
      "source": [
        " #using Breast Cancer Wisconsin data from UCI\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data',\n",
        "                  header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset has 30 features. The first two columns are sample ID number and the target label (M=malignant, B=benign)."
      ],
      "metadata": {
        "id": "7G9fY2owb5Ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use LabelEncoder to transform class label from 'M', 'B' to integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#assign the 30 features to NumPy array\n",
        "X = df.loc[:, 2:].values\n",
        "y = df.loc[:, 1].values  #target labels\n",
        "\n",
        "#initialize labelencoder object\n",
        "le = LabelEncoder()\n",
        "\n",
        "#transform target labels\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "q3MjB6qqcTIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#double check the mapping\n",
        "le.transform(['M', 'B'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48FsPNZ6dJhT",
        "outputId": "a67233a1-ebd5-43f6-8f0c-6d6ecffc6e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "^ so M -> 1 and B -> 0"
      ],
      "metadata": {
        "id": "c7jbGHM3dZxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,\n",
        "                                                    stratify=y,\n",
        "                                                    random_state=1)"
      ],
      "metadata": {
        "id": "Slib2g7ldWCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use a logistic regression model to predict 'Benign' or 'Malignant'. The logistic regression model requires all features to be on the same scale, so we'll standardize the data. Let's also say we want to compress our data from 30 dimensions into two dimensions. Instead of going through the data transformation and model fitting for the training and test sets individually, we can package the following objects into one pipeline:\n",
        "\n",
        "- `StandardScaler`\n",
        "- `PCA`\n",
        "- `LogisticRegression`"
      ],
      "metadata": {
        "id": "NDvMN9E2eCU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "#instantiate pipeline object\n",
        "pipe_lr = make_pipeline(StandardScaler(),\n",
        "                        PCA(n_components=2),\n",
        "                        LogisticRegression())\n",
        "#fit to data, fit method\n",
        "pipe_lr.fit(X_train, y_train)\n",
        "\n",
        "#predict on test set, predict method\n",
        "y_pred = pipe_lr.predict(X_test)\n",
        "\n",
        "#get accuracy score, score method\n",
        "test_acc = pipe_lr.score(X_test, y_test)\n",
        "\n",
        "print(f'Test Accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoOpqBaAfeDK",
        "outputId": "315be031-1b04-4dfa-d583-758abb28e7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `make_pipeline` object takes in any transformers (objects that have `fit` and `transform` methods) and an estimator that has `fit` and `predict` methods.\n",
        "\n",
        "When we call `fit` method on the `pipe_lr` object, the `StandardScaler` fit and transformed the data. The the transformed data is passed to `PCA`, where it fits to and transforms the data. Then that transformed data is passed to the estimator `LogisticRegression` which fits to it.\n",
        "\n",
        "When we pass in a dataset to the `predict` call of the pipeline object, the data will pass through the transforms (NOT the fits! The transformers and estimator have already been fit!) and then into the estimator, which will return predictions on the transformed data."
      ],
      "metadata": {
        "id": "CbtCX6ckg2wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "#K-fold cross-validation"
      ],
      "metadata": {
        "id": "g_x0pKZIo84Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(estimator=pipe_lr,           #the pipe object we created above\n",
        "                         X=X_train,\n",
        "                         y=y_train,\n",
        "                         cv=10,                       #the number of folds\n",
        "                         n_jobs=1)                    #number of CPUs to use\n",
        "print(f'Accuracy scores: {scores}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etpBV086j7XO",
        "outputId": "fe522101-a9c2-4ef1-b545-af5e7778a7f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy scores: [0.93478261 0.93478261 0.95652174 0.95652174 0.93478261 0.95555556\n",
            " 0.97777778 0.93333333 0.95555556 0.95555556]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#mean score +- one std deviation\n",
        "print(f'Average Accuracy Estimate: {np.mean(scores):.3f}' f'+/- {np.std(scores):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ol2MvEpqL-f",
        "outputId": "9cf62398-fb6b-4082-cfb6-945c3c675729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy Estimate: 0.950+/- 0.014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "^ the `:.3f` inside the `{}` in the print statement rounds the number to 3 decimal places I think..."
      ],
      "metadata": {
        "id": "XkRevjhWq_4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "4gDYRA5IrTLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#same thing using StratifiedKFold iterator\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "#instantiate iterator object\n",
        "kfold = StratifiedKFold(n_splits=10,).split(X_train, y_train)\n",
        "\n",
        "scores = []\n",
        "\n",
        "for k, (train, test) in enumerate(kfold):\n",
        "  pipe_lr.fit(X_train[train], y_train[train])\n",
        "  score = pipe_lr.score(X_train[test], y_train[test])\n",
        "  scores.append(score)\n",
        "  print(f'fold: {k+1}, ' f'Class distr.: {np.bincount(y_train[train])}, '\n",
        "        f'Accuracy: {score:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYjMPZYzrKgV",
        "outputId": "08a3d1f7-b886-4c3c-acc8-1f8e50a0386e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold: 1, Class distr.: [256 153], Accuracy: 0.935\n",
            "fold: 2, Class distr.: [256 153], Accuracy: 0.935\n",
            "fold: 3, Class distr.: [256 153], Accuracy: 0.957\n",
            "fold: 4, Class distr.: [256 153], Accuracy: 0.957\n",
            "fold: 5, Class distr.: [256 153], Accuracy: 0.935\n",
            "fold: 6, Class distr.: [257 153], Accuracy: 0.956\n",
            "fold: 7, Class distr.: [257 153], Accuracy: 0.978\n",
            "fold: 8, Class distr.: [257 153], Accuracy: 0.933\n",
            "fold: 9, Class distr.: [257 153], Accuracy: 0.956\n",
            "fold: 10, Class distr.: [257 153], Accuracy: 0.956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "^ notice how for each fold, the number of benign and malignant examples are the same - this is what the \"stratified\" version does!"
      ],
      "metadata": {
        "id": "1QVZJd5xuHPf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4XxsAKXtuhMS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}